{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbe2cd7f-3ef2-4436-8484-bb9a37c2e11f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://clv-prediction-data/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'clv-prediction-data' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n",
      "Project: clv-prediction-mlops\n",
      "Bucket: gs://clv-prediction-data\n",
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "# 01-data-preparation.ipynb\n",
    "# Customer Lifetime Value Prediction - Data Preparation\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ID = \"clv-prediction-mlops\"\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = \"clv-prediction-data\"\n",
    "\n",
    "# Create GCS bucket\n",
    "!gsutil mb -l {REGION} gs://{BUCKET_NAME}\n",
    "\n",
    "print(f\"Project: {PROJECT_ID}\")\n",
    "print(f\"Bucket: gs://{BUCKET_NAME}\")\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d586bd0-35e1-4e0c-8ba1-03b5ea8c3f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheets: ['Year 2009-2010', 'Year 2010-2011']\n",
      "\n",
      "Total rows: 1,067,371\n",
      "Date range: 2009-12-01 07:45:00 to 2011-12-09 12:50:00\n",
      "\n",
      "Columns: ['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'Price', 'Customer ID', 'Country']\n",
      "\n",
      "Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Invoice</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>Price</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>489434</td>\n",
       "      <td>85048</td>\n",
       "      <td>15CM CHRISTMAS GLASS BALL 20 LIGHTS</td>\n",
       "      <td>12</td>\n",
       "      <td>2009-12-01 07:45:00</td>\n",
       "      <td>6.95</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489434</td>\n",
       "      <td>79323P</td>\n",
       "      <td>PINK CHERRY LIGHTS</td>\n",
       "      <td>12</td>\n",
       "      <td>2009-12-01 07:45:00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489434</td>\n",
       "      <td>79323W</td>\n",
       "      <td>WHITE CHERRY LIGHTS</td>\n",
       "      <td>12</td>\n",
       "      <td>2009-12-01 07:45:00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>489434</td>\n",
       "      <td>22041</td>\n",
       "      <td>RECORD FRAME 7\" SINGLE SIZE</td>\n",
       "      <td>48</td>\n",
       "      <td>2009-12-01 07:45:00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>489434</td>\n",
       "      <td>21232</td>\n",
       "      <td>STRAWBERRY CERAMIC TRINKET BOX</td>\n",
       "      <td>24</td>\n",
       "      <td>2009-12-01 07:45:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Invoice StockCode                          Description  Quantity  \\\n",
       "0  489434     85048  15CM CHRISTMAS GLASS BALL 20 LIGHTS        12   \n",
       "1  489434    79323P                   PINK CHERRY LIGHTS        12   \n",
       "2  489434    79323W                  WHITE CHERRY LIGHTS        12   \n",
       "3  489434     22041         RECORD FRAME 7\" SINGLE SIZE         48   \n",
       "4  489434     21232       STRAWBERRY CERAMIC TRINKET BOX        24   \n",
       "\n",
       "          InvoiceDate  Price  Customer ID         Country  \n",
       "0 2009-12-01 07:45:00   6.95      13085.0  United Kingdom  \n",
       "1 2009-12-01 07:45:00   6.75      13085.0  United Kingdom  \n",
       "2 2009-12-01 07:45:00   6.75      13085.0  United Kingdom  \n",
       "3 2009-12-01 07:45:00   2.10      13085.0  United Kingdom  \n",
       "4 2009-12-01 07:45:00   1.25      13085.0  United Kingdom  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download UCI Online Retail II dataset\n",
    "!pip install openpyxl --quiet\n",
    "\n",
    "!wget -q https://archive.ics.uci.edu/ml/machine-learning-databases/00502/online_retail_II.xlsx -O /tmp/retail.xlsx\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel('/tmp/retail.xlsx', sheet_name=None)\n",
    "\n",
    "# Dataset has 2 sheets (Year 2009-2010 and Year 2010-2011)\n",
    "print(\"Sheets:\", list(df.keys()))\n",
    "\n",
    "# Combine both sheets\n",
    "df_2009 = df['Year 2009-2010']\n",
    "df_2010 = df['Year 2010-2011']\n",
    "\n",
    "data = pd.concat([df_2009, df_2010], ignore_index=True)\n",
    "\n",
    "print(f\"\\nTotal rows: {len(data):,}\")\n",
    "print(f\"Date range: {data['InvoiceDate'].min()} to {data['InvoiceDate'].max()}\")\n",
    "print(f\"\\nColumns: {list(data.columns)}\")\n",
    "print(f\"\\nSample:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a9bee1-946c-499c-90b1-fba35e32c259",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA QUALITY CHECK\n",
      "============================================================\n",
      "\n",
      "Missing values:\n",
      "Invoice             0\n",
      "StockCode           0\n",
      "Description      4382\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "Price               0\n",
      "Customer ID    243007\n",
      "Country             0\n",
      "dtype: int64\n",
      "\n",
      "Unique customers: 5,942\n",
      "Unique products: 5,305\n",
      "Unique countries: 43\n",
      "\n",
      "Negative quantities (returns): 22,950\n",
      "Zero/negative prices: 6,207\n"
     ]
    }
   ],
   "source": [
    "# Data quality check\n",
    "print(\"=\"*60)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nMissing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "print(f\"\\nUnique customers: {data['Customer ID'].nunique():,}\")\n",
    "print(f\"Unique products: {data['StockCode'].nunique():,}\")\n",
    "print(f\"Unique countries: {data['Country'].nunique()}\")\n",
    "\n",
    "print(f\"\\nNegative quantities (returns): {(data['Quantity'] < 0).sum():,}\")\n",
    "print(f\"Zero/negative prices: {(data['Price'] <= 0).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba8f6f3-032a-4ed6-b7cc-d4c26f4a5356",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA CLEANING\n",
      "============================================================\n",
      "Starting rows: 1,067,371\n",
      "After removing null Customer ID: 824,364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_4216/1890868398.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean['Customer ID'] = data_clean['Customer ID'].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing cancellations: 805,620\n",
      "After removing zero/negative prices: 805,549\n",
      "After removing returns: 805,549\n",
      "\n",
      "Final dataset: 805,549 rows\n",
      "Unique customers: 5,878\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "print(\"=\"*60)\n",
    "print(\"DATA CLEANING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Starting count\n",
    "print(f\"Starting rows: {len(data):,}\")\n",
    "\n",
    "# Remove rows without Customer ID (can't calculate CLV without it)\n",
    "data_clean = data.dropna(subset=['Customer ID'])\n",
    "print(f\"After removing null Customer ID: {len(data_clean):,}\")\n",
    "\n",
    "# Convert Customer ID to integer\n",
    "data_clean['Customer ID'] = data_clean['Customer ID'].astype(int)\n",
    "\n",
    "# Remove cancelled orders (Invoice starts with 'C')\n",
    "data_clean = data_clean[~data_clean['Invoice'].astype(str).str.startswith('C')]\n",
    "print(f\"After removing cancellations: {len(data_clean):,}\")\n",
    "\n",
    "# Remove zero/negative prices\n",
    "data_clean = data_clean[data_clean['Price'] > 0]\n",
    "print(f\"After removing zero/negative prices: {len(data_clean):,}\")\n",
    "\n",
    "# Calculate line total\n",
    "data_clean['Total'] = data_clean['Quantity'] * data_clean['Price']\n",
    "\n",
    "# Keep only positive totals (remove returns for now)\n",
    "data_clean = data_clean[data_clean['Total'] > 0]\n",
    "print(f\"After removing returns: {len(data_clean):,}\")\n",
    "\n",
    "print(f\"\\nFinal dataset: {len(data_clean):,} rows\")\n",
    "print(f\"Unique customers: {data_clean['Customer ID'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "697a5690-8627-4bbb-9deb-cb72beba7483",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'clv-predictions-mlops:retail_data' successfully created.\n"
     ]
    }
   ],
   "source": [
    "!bq mk --dataset clv-predictions-mlops:retail_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c580bd6-43d7-4879-82e2-48f9e48a5c97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r99dc24d65a1b05f_0000019b0afebec5_1 ... (3s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "#load data into BigQuery\n",
    "!bq load \\\n",
    "    --source_format=PARQUET \\\n",
    "    --replace \\\n",
    "    clv-predictions-mlops:retail_data.transactions \\\n",
    "    gs://clv-prediction-data/raw/transactions.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48dcca00-e92d-4277-a739-1bcd68ea0890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "| row_count |\n",
      "+-----------+\n",
      "|    805549 |\n",
      "+-----------+\n"
     ]
    }
   ],
   "source": [
    "#confirm data is in BigQuery\n",
    "!bq query --use_legacy_sql=false \\\n",
    "    'SELECT COUNT(*) as row_count FROM `clv-predictions-mlops.retail_data.transactions`'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93bde79c-cb87-4e76-9d7e-17e0b5cd3191",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------------------+\n",
      "|      earliest       |       latest        |\n",
      "+---------------------+---------------------+\n",
      "| 2009-12-01 07:45:00 | 2011-12-09 12:50:00 |\n",
      "+---------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check date range - convert nanoseconds to timestamp\n",
    "!bq query --use_legacy_sql=false 'SELECT TIMESTAMP_MICROS(CAST(MIN(InvoiceDate)/1000 AS INT64)) as earliest, TIMESTAMP_MICROS(CAST(MAX(InvoiceDate)/1000 AS INT64)) as latest FROM `clv-predictions-mlops.retail_data.transactions`'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "993d3252-11ee-404f-9e68-0279568bb8e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created customer_features table\n"
     ]
    }
   ],
   "source": [
    "# Calculate RFM features from first 12 months (Dec 2009 - Nov 2010)\n",
    "# These features will predict spend in months 13-24\n",
    "\n",
    "query = \"\"\"\n",
    "CREATE OR REPLACE TABLE `clv-predictions-mlops.retail_data.customer_features` AS\n",
    "\n",
    "WITH feature_period AS (\n",
    "    -- First 12 months of data for building features\n",
    "    SELECT *,\n",
    "        TIMESTAMP_MICROS(CAST(InvoiceDate/1000 AS INT64)) AS purchase_time\n",
    "    FROM `clv-predictions-mlops.retail_data.transactions`\n",
    "    WHERE TIMESTAMP_MICROS(CAST(InvoiceDate/1000 AS INT64)) < '2010-12-01'\n",
    "),\n",
    "\n",
    "target_period AS (\n",
    "    -- Next 12 months for target variable (what we predict)\n",
    "    SELECT *,\n",
    "        TIMESTAMP_MICROS(CAST(InvoiceDate/1000 AS INT64)) AS purchase_time\n",
    "    FROM `clv-predictions-mlops.retail_data.transactions`\n",
    "    WHERE TIMESTAMP_MICROS(CAST(InvoiceDate/1000 AS INT64)) >= '2010-12-01'\n",
    "),\n",
    "\n",
    "rfm_features AS (\n",
    "    -- Calculate RFM for each customer from feature period\n",
    "    SELECT \n",
    "        `Customer ID`,\n",
    "        \n",
    "        -- Recency: days since last purchase (from end of feature period)\n",
    "        DATE_DIFF(DATE('2010-12-01'), DATE(MAX(purchase_time)), DAY) AS recency_days,\n",
    "        \n",
    "        -- Frequency: number of unique orders\n",
    "        COUNT(DISTINCT Invoice) AS frequency,\n",
    "        \n",
    "        -- Monetary: total spend\n",
    "        ROUND(SUM(Quantity * Price), 2) AS monetary\n",
    "        \n",
    "    FROM feature_period\n",
    "    GROUP BY `Customer ID`\n",
    "),\n",
    "\n",
    "target AS (\n",
    "    -- Calculate target: total spend in months 13-24\n",
    "    SELECT \n",
    "        `Customer ID`,\n",
    "        ROUND(SUM(Quantity * Price), 2) AS target_clv\n",
    "    FROM target_period\n",
    "    GROUP BY `Customer ID`\n",
    ")\n",
    "\n",
    "-- Join features with target\n",
    "SELECT \n",
    "    r.*,\n",
    "    COALESCE(t.target_clv, 0) AS target_clv  -- 0 if customer didn't buy in target period\n",
    "FROM rfm_features r\n",
    "LEFT JOIN target t ON r.`Customer ID` = t.`Customer ID`\n",
    "\"\"\"\n",
    "\n",
    "# Run it\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project=\"clv-predictions-mlops\")\n",
    "job = client.query(query)\n",
    "job.result()\n",
    "print(\"Created customer_features table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dc37847-113b-470c-a670-7efe2f231cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "| customers |\n",
      "+-----------+\n",
      "|      4266 |\n",
      "+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Check the features table\n",
    "!bq query --use_legacy_sql=false 'SELECT COUNT(*) as customers FROM `clv-predictions-mlops.retail_data.customer_features`'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "965a4988-f8c7-4c40-bad6-fd39677f076e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+-----------+----------+------------+\n",
      "| Customer ID | recency_days | frequency | monetary | target_clv |\n",
      "+-------------+--------------+-----------+----------+------------+\n",
      "|       16473 |            1 |         1 |   154.72 |     316.11 |\n",
      "|       17820 |            1 |         1 |   183.56 |        0.0 |\n",
      "|       17378 |            1 |         1 |    10.95 |        0.0 |\n",
      "|       15939 |            1 |         1 |  2945.38 |    6115.01 |\n",
      "|       17826 |            1 |         1 |   134.59 |        0.0 |\n",
      "+-------------+--------------+-----------+----------+------------+\n"
     ]
    }
   ],
   "source": [
    "# Preview sample rows\n",
    "!bq query --use_legacy_sql=false 'SELECT * FROM `clv-predictions-mlops.retail_data.customer_features` LIMIT 5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb6fc626-2c7d-4859-8d80-760230b0ec53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+-------------------+\n",
      "| min_clv | avg_clv |  max_clv  | churned_customers |\n",
      "+---------+---------+-----------+-------------------+\n",
      "|     0.0 | 1743.76 | 287491.91 |              1540 |\n",
      "+---------+---------+-----------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "# Target CLV distribution stats\n",
    "!bq query --use_legacy_sql=false 'SELECT ROUND(MIN(target_clv),2) as min_clv, ROUND(AVG(target_clv),2) as avg_clv, ROUND(MAX(target_clv),2) as max_clv, COUNTIF(target_clv = 0) as churned_customers FROM `clv-predictions-mlops.retail_data.customer_features`'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac8f682b-0411-4469-984a-642772ec39d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated customer_features with expanded feature set\n"
     ]
    }
   ],
   "source": [
    "# Expanded feature set - more behavioral signals\n",
    "query = \"\"\"\n",
    "CREATE OR REPLACE TABLE `clv-predictions-mlops.retail_data.customer_features` AS\n",
    "\n",
    "WITH feature_period AS (\n",
    "    SELECT *,\n",
    "        TIMESTAMP_MICROS(CAST(InvoiceDate/1000 AS INT64)) AS purchase_time,\n",
    "        Quantity * Price AS line_total\n",
    "    FROM `clv-predictions-mlops.retail_data.transactions`\n",
    "    WHERE TIMESTAMP_MICROS(CAST(InvoiceDate/1000 AS INT64)) < '2010-12-01'\n",
    "),\n",
    "\n",
    "target_period AS (\n",
    "    SELECT *,\n",
    "        Quantity * Price AS line_total\n",
    "    FROM `clv-predictions-mlops.retail_data.transactions`\n",
    "    WHERE TIMESTAMP_MICROS(CAST(InvoiceDate/1000 AS INT64)) >= '2010-12-01'\n",
    "),\n",
    "\n",
    "customer_features AS (\n",
    "    SELECT \n",
    "        `Customer ID`,\n",
    "        \n",
    "        -- RFM Features\n",
    "        DATE_DIFF(DATE('2010-12-01'), DATE(MAX(purchase_time)), DAY) AS recency_days,\n",
    "        COUNT(DISTINCT Invoice) AS frequency,\n",
    "        ROUND(SUM(line_total), 2) AS monetary,\n",
    "        \n",
    "        -- Order-level features\n",
    "        ROUND(SUM(line_total) / COUNT(DISTINCT Invoice), 2) AS avg_order_value,\n",
    "        ROUND(COUNT(DISTINCT Invoice) / 12.0, 2) AS orders_per_month,\n",
    "        \n",
    "        -- Item-level features\n",
    "        COUNT(*) AS total_items_purchased,\n",
    "        COUNT(DISTINCT StockCode) AS unique_products,\n",
    "        ROUND(AVG(Quantity), 2) AS avg_quantity_per_line,\n",
    "        ROUND(AVG(Price), 2) AS avg_unit_price,\n",
    "        \n",
    "        -- Time-based features\n",
    "        DATE_DIFF(DATE(MAX(purchase_time)), DATE(MIN(purchase_time)), DAY) AS customer_tenure_days,\n",
    "        COUNT(DISTINCT DATE(purchase_time)) AS unique_purchase_days,\n",
    "        \n",
    "        -- Engagement features\n",
    "        ROUND(COUNT(DISTINCT StockCode) / COUNT(DISTINCT Invoice), 2) AS products_per_order\n",
    "        \n",
    "    FROM feature_period\n",
    "    GROUP BY `Customer ID`\n",
    "),\n",
    "\n",
    "target AS (\n",
    "    SELECT \n",
    "        `Customer ID`,\n",
    "        ROUND(SUM(line_total), 2) AS target_clv\n",
    "    FROM target_period\n",
    "    GROUP BY `Customer ID`\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    f.*,\n",
    "    COALESCE(t.target_clv, 0) AS target_clv\n",
    "FROM customer_features f\n",
    "LEFT JOIN target t ON f.`Customer ID` = t.`Customer ID`\n",
    "\"\"\"\n",
    "\n",
    "client = bigquery.Client(project=\"clv-predictions-mlops\")\n",
    "job = client.query(query)\n",
    "job.result()\n",
    "print(\"Updated customer_features with expanded feature set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8144dd9-009f-42cb-a375-8e265d5c64a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install PySpark\n",
    "!pip install pyspark -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f6967c7-74c3-4c45-9948-01c336df2699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable dataproc.googleapis.com --project=clv-predictions-mlops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c44a787c-2b10-4e50-a7b1-51cc79440bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on operation [projects/clv-predictions-mlops/regions/us-central1/operations/109c126e-6898-38a6-a727-ec7734a9b49d].\n",
      "Waiting for cluster creation operation...                                      \n",
      "\u001b[1;33mWARNING:\u001b[0m Consider using Auto Zone rather than selecting a zone manually. See https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone\n",
      "\u001b[1;33mWARNING:\u001b[0m For PD-Standard without local SSDs, we strongly recommend provisioning 1TB or larger to ensure consistently high I/O performance. See https://cloud.google.com/compute/docs/disks/performance for information on disk I/O performance.\n",
      "\u001b[1;33mWARNING:\u001b[0m Permissions are missing for the default service account '674754622820-compute@developer.gserviceaccount.com', missing permissions: [storage.buckets.get, storage.objects.create, storage.objects.delete, storage.objects.get, storage.objects.list, storage.objects.update] on the project 'projects/clv-predictions-mlops'. This usually happens when a custom resource (ex: custom staging bucket) or a user-managed VM Service account has been provided and the default/user-managed service account hasn't been granted enough permissions on the resource. See https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/service-accounts#VM_service_account.\n",
      "\u001b[1;33mWARNING:\u001b[0m The firewall rules for specified network or subnetwork would allow ingress traffic from 0.0.0.0/0, which could be a security risk.\n",
      "Waiting for cluster creation operation...done.                                 \n",
      "Created [https://dataproc.googleapis.com/v1/projects/clv-predictions-mlops/regions/us-central1/clusters/clv-spark-cluster] Cluster placed in zone [us-central1-a].\n"
     ]
    }
   ],
   "source": [
    "# Create Dataproc cluster\n",
    "!gcloud dataproc clusters create clv-spark-cluster \\\n",
    "    --region=us-central1 \\\n",
    "    --zone=us-central1-a \\\n",
    "    --single-node \\\n",
    "    --master-machine-type=n1-standard-4 \\\n",
    "    --master-boot-disk-size=100GB \\\n",
    "    --image-version=2.1-debian11 \\\n",
    "    --project=clv-predictions-mlops \\\n",
    "    --enable-component-gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67946e71-a5e2-46a3-9ad0-947452fab0b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script written\n"
     ]
    }
   ],
   "source": [
    "script = '''from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CLV-TextFeatures\").getOrCreate()\n",
    "\n",
    "transactions = spark.read.format(\"bigquery\").option(\"table\", \"clv-predictions-mlops.retail_data.transactions\").load()\n",
    "\n",
    "transactions = transactions.withColumn(\"purchase_time\", (F.col(\"InvoiceDate\") / 1000000000).cast(TimestampType()))\n",
    "\n",
    "cutoff = F.lit(\"2010-12-01\").cast(TimestampType())\n",
    "transactions = transactions.filter(F.col(\"purchase_time\") < cutoff)\n",
    "\n",
    "print(f\"Transactions after filter: {transactions.count()}\")\n",
    "\n",
    "customer_text = transactions.groupBy(\"Customer ID\").agg(\n",
    "    F.concat_ws(\" \", F.collect_list(\"Description\")).alias(\"all_descriptions\"),\n",
    "    F.count(\"*\").alias(\"num_items\"),\n",
    "    F.countDistinct(\"Description\").alias(\"unique_descriptions\")\n",
    ")\n",
    "\n",
    "customer_text = customer_text.withColumn(\"clean_text\", F.lower(F.regexp_replace(F.col(\"all_descriptions\"), \"[^a-zA-Z0-9 ]\", \" \")))\n",
    "customer_text = customer_text.withColumn(\"clean_text\", F.trim(F.regexp_replace(F.col(\"clean_text\"), \" +\", \" \")))\n",
    "\n",
    "output = customer_text.select(F.col(\"Customer ID\").alias(\"customer_id\"), \"clean_text\", \"num_items\", \"unique_descriptions\")\n",
    "\n",
    "output.write.format(\"bigquery\").option(\"table\", \"clv-predictions-mlops.retail_data.customer_text\").option(\"temporaryGcsBucket\", \"clv-prediction-data\").mode(\"overwrite\").save()\n",
    "\n",
    "print(f\"Processed {output.count()} customers\")\n",
    "spark.stop()\n",
    "'''\n",
    "\n",
    "with open(\"text_features.py\", \"w\") as f:\n",
    "    f.write(script)\n",
    "    \n",
    "print(\"Script written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d146c23-364c-4a41-b175-8f1d6bd93807",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [1676e58b3a9848a9972c2c44147646f3] submitted.\n",
      "Waiting for job output...\n",
      "25/12/11 02:08:58 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/12/11 02:08:58 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/12/11 02:08:58 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/12/11 02:08:58 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "25/12/11 02:08:59 INFO DataprocSparkPlugin: Registered 128 driver metrics\n",
      "25/12/11 02:09:00 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at clv-spark-cluster-m.us-central1-a.c.clv-predictions-mlops.internal./10.128.0.3:8032\n",
      "25/12/11 02:09:00 INFO AHSProxy: Connecting to Application History server at clv-spark-cluster-m.us-central1-a.c.clv-predictions-mlops.internal./10.128.0.3:10200\n",
      "25/12/11 02:09:01 INFO Configuration: resource-types.xml not found\n",
      "25/12/11 02:09:01 INFO ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "25/12/11 02:09:03 INFO YarnClientImpl: Submitted application application_1765418166196_0002\n",
      "25/12/11 02:09:04 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at clv-spark-cluster-m.us-central1-a.c.clv-predictions-mlops.internal./10.128.0.3:8030\n",
      "25/12/11 02:09:06 INFO GoogleCloudStorageImpl: Ignoring exception of type GoogleJsonResponseException; verified object already exists with desired state.\n",
      "25/12/11 02:09:21 INFO DirectBigQueryRelation: |Querying table clv-predictions-mlops.retail_data.transactions, parameters sent from Spark:|requiredColumns=[InvoiceDate],|filters=[IsNotNull(InvoiceDate)]\n",
      "25/12/11 02:09:24 INFO ReadSessionCreator: Requested 20000 max partitions, but only received 1 from the BigQuery Storage API for session projects/clv-predictions-mlops/locations/us/sessions/CAISDFBzOU9GU3VQQTBySxoCamQaB3l1Y2JmYWI. Notice that the number of streams in actual may be lower than the requested number, depending on the amount parallelism that is reasonable for the table and the maximum amount of parallelism allowed by the system.\n",
      "25/12/11 02:09:24 INFO BigQueryRDDFactory: Created read session for table 'clv-predictions-mlops.retail_data.transactions': projects/clv-predictions-mlops/locations/us/sessions/CAISDFBzOU9GU3VQQTBySxoCamQaB3l1Y2JmYWI\n",
      "Transactions after filter: 393160\n",
      "25/12/11 02:09:31 INFO DirectBigQueryRelation: |Querying table clv-predictions-mlops.retail_data.transactions, parameters sent from Spark:|requiredColumns=[Description,Customer ID,InvoiceDate],|filters=[IsNotNull(InvoiceDate)]\n",
      "25/12/11 02:09:32 INFO ReadSessionCreator: Requested 20000 max partitions, but only received 1 from the BigQuery Storage API for session projects/clv-predictions-mlops/locations/us/sessions/CAISDFlFNERQZEhDMWRnTBoCamQaB3l1Y2JmYWI. Notice that the number of streams in actual may be lower than the requested number, depending on the amount parallelism that is reasonable for the table and the maximum amount of parallelism allowed by the system.\n",
      "25/12/11 02:09:32 INFO BigQueryRDDFactory: Created read session for table 'clv-predictions-mlops.retail_data.transactions': projects/clv-predictions-mlops/locations/us/sessions/CAISDFlFNERQZEhDMWRnTBoCamQaB3l1Y2JmYWI\n",
      "25/12/11 02:09:55 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://clv-prediction-data/.spark-bigquery-application_1765418166196_0002-f5f51b00-7735-4fc0-81a0-017f2fc69b1e/' directory.\n",
      "25/12/11 02:09:57 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=retail_data, projectId=clv-predictions-mlops, tableId=customer_text}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_TRUNCATE, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=null, ignoreUnknownValue=null, sourceUris=[gs://clv-prediction-data/.spark-bigquery-application_1765418166196_0002-f5f51b00-7735-4fc0-81a0-017f2fc69b1e/part-00001-740d2932-cf6e-4355-8fbc-e883ffe82fbf-c000.snappy.parquet, gs://clv-prediction-data/.spark-bigquery-application_1765418166196_0002-f5f51b00-7735-4fc0-81a0-017f2fc69b1e/part-00002-740d2932-cf6e-4355-8fbc-e883ffe82fbf-c000.snappy.parquet, gs://clv-prediction-data/.spark-bigquery-application_1765418166196_0002-f5f51b00-7735-4fc0-81a0-017f2fc69b1e/part-00000-740d2932-cf6e-4355-8fbc-e883ffe82fbf-c000.snappy.parquet, gs://clv-prediction-data/.spark-bigquery-application_1765418166196_0002-f5f51b00-7735-4fc0-81a0-017f2fc69b1e/part-00003-740d2932-cf6e-4355-8fbc-e883ffe82fbf-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=true, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=clv-predictions-mlops, job=273962f2-4a18-45f8-bef3-322571463304, location=US}\n",
      "25/12/11 02:10:00 INFO BigQueryClient: Done loading to clv-predictions-mlops.retail_data.customer_text. jobId: JobId{project=clv-predictions-mlops, job=273962f2-4a18-45f8-bef3-322571463304, location=US}\n",
      "25/12/11 02:10:01 INFO DirectBigQueryRelation: |Querying table clv-predictions-mlops.retail_data.transactions, parameters sent from Spark:|requiredColumns=[Customer ID,InvoiceDate],|filters=[IsNotNull(InvoiceDate)]\n",
      "25/12/11 02:10:01 INFO ReadSessionCreator: Requested 20000 max partitions, but only received 1 from the BigQuery Storage API for session projects/clv-predictions-mlops/locations/us/sessions/CAISDFFmNFVzb2oxWm15ORoCamQaB3l1Y2JmYWI. Notice that the number of streams in actual may be lower than the requested number, depending on the amount parallelism that is reasonable for the table and the maximum amount of parallelism allowed by the system.\n",
      "25/12/11 02:10:01 INFO BigQueryRDDFactory: Created read session for table 'clv-predictions-mlops.retail_data.transactions': projects/clv-predictions-mlops/locations/us/sessions/CAISDFFmNFVzb2oxWm15ORoCamQaB3l1Y2JmYWI\n",
      "Processed 4266 customers\n",
      "25/12/11 02:10:04 INFO DataprocSparkPlugin: Shutting down driver plugin. metrics=[files_created=2, gcs_api_server_not_implemented_error_count=0, gcs_api_server_timeout_count=0, action_http_post_request_failures=0, op_get_list_status_result_size=5, op_open=0, gcs_api_client_unauthorized_response_count=0, action_http_head_request_failures=0, stream_read_close_operations=0, stream_read_bytes_backwards_on_seek=0, exception_count=33, gcs_api_total_request_count=47, op_create=2, gcs_api_client_bad_request_count=0, op_create_non_recursive=0, gcs_api_client_gone_response_count=0, stream_write_operations=0, stream_read_operations=0, gcs_api_client_request_timeout_count=0, op_rename=0, op_get_file_status=4, stream_read_total_bytes=0, op_glob_status=0, stream_read_exceptions=0, action_http_get_request_failures=0, op_exists=0, stream_write_bytes=484860, op_xattr_list=0, stream_write_exceptions=0, gcs_api_server_unavailable_count=0, directories_created=0, files_delete_rejected=0, op_xattr_get_named=0, op_hsync=0, stream_read_operations_incomplete=0, op_delete=3, stream_read_bytes=0, gcs_api_client_non_found_response_count=19, gcs_api_client_requested_range_not_statisfiable_count=0, op_hflush=0, op_list_status=1, op_xattr_get_named_map=0, gcs_api_client_side_error_count=50, op_get_file_checksum=0, action_http_delete_request_failures=0, gcs_api_server_internal_error_count=0, stream_read_seek_bytes_skipped=0, stream_write_close_operations=1, op_list_files=0, files_deleted=0, op_mkdirs=2, gcs_api_client_rate_limit_error_count=0, action_http_put_request_failures=0, gcs_api_server_bad_gateway_count=0, stream_read_seek_backward_operations=0, gcs_api_server_side_error_count=0, action_http_patch_request_failures=0, stream_read_seek_operations=0, stream_read_seek_forward_operations=0, gcs_api_client_precondition_failed_response_count=1, directories_deleted=0, op_xattr_get_map=0, delegation_tokens_issued=0, op_create_min=428, op_delete_min=199, op_mkdirs_min=302, op_create_non_recursive_min=0, op_glob_status_min=0, op_hsync_min=0, op_xattr_get_named_min=0, op_list_status_min=179, op_xattr_get_named_map_min=0, stream_read_close_operations_min=0, stream_read_operations_min=0, stream_read_seek_operations_min=0, op_hflush_min=0, op_xattr_get_map_min=0, op_xattr_list_min=0, stream_write_operations_min=0, op_get_file_status_min=140, op_open_min=0, op_rename_min=0, delegation_tokens_issued_min=0, stream_write_close_operations_min=151, stream_read_close_operations_max=0, stream_read_operations_max=0, stream_read_seek_operations_max=0, op_hflush_max=0, op_xattr_list_max=0, op_xattr_get_map_max=0, op_xattr_get_named_max=0, op_create_non_recursive_max=0, op_glob_status_max=0, op_get_file_status_max=470, stream_write_close_operations_max=151, op_open_max=0, delegation_tokens_issued_max=0, op_mkdirs_max=448, op_rename_max=0, op_create_max=476, op_delete_max=463, op_list_status_max=179, op_xattr_get_named_map_max=0, stream_write_operations_max=0, op_hsync_max=0, op_list_status_mean=179, stream_read_close_operations_mean=0, op_open_mean=0, op_xattr_get_named_map_mean=0, op_xattr_list_mean=0, op_mkdirs_mean=375, stream_write_close_operations_mean=151, op_rename_mean=0, op_hsync_mean=0, delegation_tokens_issued_mean=0, stream_read_operations_mean=0, op_xattr_get_map_mean=0, op_create_mean=452, op_glob_status_mean=0, op_delete_mean=317, stream_read_seek_operations_mean=0, stream_write_operations_mean=0, op_create_non_recursive_mean=0, op_hflush_mean=0, op_xattr_get_named_mean=0, op_get_file_status_mean=258, stream_write_operations_duration=0, stream_read_operations_duration=0]\n",
      "Job [1676e58b3a9848a9972c2c44147646f3] finished successfully.\n",
      "done: true\n",
      "driverControlFilesUri: gs://dataproc-staging-us-central1-674754622820-rpqnk15y/google-cloud-dataproc-metainfo/eef52c40-070e-4c8a-9039-2ff5fd0abe47/jobs/1676e58b3a9848a9972c2c44147646f3/\n",
      "driverOutputResourceUri: gs://dataproc-staging-us-central1-674754622820-rpqnk15y/google-cloud-dataproc-metainfo/eef52c40-070e-4c8a-9039-2ff5fd0abe47/jobs/1676e58b3a9848a9972c2c44147646f3/driveroutput\n",
      "jobUuid: 3def5609-56b8-39de-8f6d-77521c670295\n",
      "placement:\n",
      "  clusterName: clv-spark-cluster\n",
      "  clusterUuid: eef52c40-070e-4c8a-9039-2ff5fd0abe47\n",
      "pysparkJob:\n",
      "  jarFileUris:\n",
      "  - gs://spark-lib/bigquery/spark-bigquery-with-dependencies_2.12-0.32.2.jar\n",
      "  mainPythonFileUri: gs://dataproc-staging-us-central1-674754622820-rpqnk15y/google-cloud-dataproc-metainfo/eef52c40-070e-4c8a-9039-2ff5fd0abe47/jobs/1676e58b3a9848a9972c2c44147646f3/staging/text_features.py\n",
      "reference:\n",
      "  jobId: 1676e58b3a9848a9972c2c44147646f3\n",
      "  projectId: clv-predictions-mlops\n",
      "status:\n",
      "  state: DONE\n",
      "  stateStartTime: '2025-12-11T02:10:05.636142Z'\n",
      "statusHistory:\n",
      "- state: PENDING\n",
      "  stateStartTime: '2025-12-11T02:08:50.794509Z'\n",
      "- state: SETUP_DONE\n",
      "  stateStartTime: '2025-12-11T02:08:50.812120Z'\n",
      "- details: Agent reported job success\n",
      "  state: RUNNING\n",
      "  stateStartTime: '2025-12-11T02:08:51.099275Z'\n",
      "yarnApplications:\n",
      "- name: CLV-TextFeatures\n",
      "  progress: 1.0\n",
      "  state: FINISHED\n",
      "  trackingUrl: http://clv-spark-cluster-m.us-central1-a.c.clv-predictions-mlops.internal.:8088/proxy/application_1765418166196_0002/\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs submit pyspark text_features.py \\\n",
    "    --cluster=clv-spark-cluster \\\n",
    "    --region=us-central1 \\\n",
    "    --jars=gs://spark-lib/bigquery/spark-bigquery-with-dependencies_2.12-0.32.2.jar \\\n",
    "    --project=clv-predictions-mlops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1737f530-9925-4162-93d6-2b26600c8a24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "| customers |\n",
      "+-----------+\n",
      "|      4266 |\n",
      "+-----------+\n"
     ]
    }
   ],
   "source": [
    "!bq query --use_legacy_sql=false 'SELECT COUNT(*) as customers FROM `clv-predictions-mlops.retail_data.customer_text`'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "91d1a4ca-f55d-4d44-99f1-ada2fe78a382",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------------------------+-----------+\n",
      "| customer_id |            text_preview             | num_items |\n",
      "+-------------+-------------------------------------+-----------+\n",
      "|       12362 | postage                             |         1 |\n",
      "|       12404 | adjustment by john on 26 01 2010 16 |         1 |\n",
      "|       12466 | adjustment by john on 26 01 2010 16 |         1 |\n",
      "+-------------+-------------------------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Preview the text data\n",
    "!bq query --use_legacy_sql=false 'SELECT customer_id, LEFT(clean_text, 100) as text_preview, num_items FROM `clv-predictions-mlops.retail_data.customer_text` LIMIT 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "759d164e-7807-4546-b736-9e519c4d2328",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on operation [projects/clv-predictions-mlops/regions/us-central1/operations/334b2792-0969-314e-813c-529ee4827c06].\n",
      "Waiting for cluster deletion operation...done.                                 \n",
      "Deleted [https://dataproc.googleapis.com/v1/projects/clv-predictions-mlops/regions/us-central1/clusters/clv-spark-cluster].\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc clusters delete clv-spark-cluster --region=us-central1 --quiet --project=clv-predictions-mlops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2b43dd3-55c4-4dda-a189-f9f4df813712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pull text data to notebook\n",
    "!pip install sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02212a90-bbd5-4471-8e5c-580a5a2bbca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4266 customers\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Load text data from BigQuery\n",
    "query = \"SELECT customer_id, clean_text FROM `clv-predictions-mlops.retail_data.customer_text`\"\n",
    "client = bigquery.Client(project=\"clv-predictions-mlops\")\n",
    "text_df = client.query(query).to_dataframe()\n",
    "\n",
    "print(f\"Loaded {len(text_df)} customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "773b8de2-2d87-4e5e-b498-769c0626a203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5bf1f635234318b3e7b59374ac3d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6cdda63723d43afb70d8e5a979f86de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd48c8ede654f7bae54f2a6b4e8728c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009f79c3a2624f5586fd855296fcc9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52722866ff974b75a6f10f02a1188cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18d73fe0ed9443cb93f33a78d61bd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3c6919588e4420a86bf8672dc66490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc06e9c366dc479db24c9ca13408ac85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211f9eae4c914caeacf74034ba62eff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec10ae3ad08475e8ec92f343697f85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a281d32a590d4be4945f294ce89a3aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6a9c971c8f47f9a1120d6ae47726e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (4266, 384)\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(text_df['clean_text'].tolist(), show_progress_bar=True)\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a7789834-0646-47a6-9036-64b703c1ea29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: (4266, 14)\n",
      "Columns: ['Customer ID', 'recency_days', 'frequency', 'monetary', 'avg_order_value', 'orders_per_month', 'total_items_purchased', 'unique_products', 'avg_quantity_per_line', 'avg_unit_price', 'customer_tenure_days', 'unique_purchase_days', 'products_per_order', 'target_clv']\n"
     ]
    }
   ],
   "source": [
    "# Get numerical features from BigQuery\n",
    "features_query = \"SELECT * FROM `clv-predictions-mlops.retail_data.customer_features`\"\n",
    "features_df = client.query(features_query).to_dataframe()\n",
    "\n",
    "print(f\"Numerical features: {features_df.shape}\")\n",
    "print(f\"Columns: {features_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ffc2860-26c9-4151-85e2-1722b7960b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset: (4266, 398)\n",
      "Features: 12 numerical + 384 embeddings = 396 features + customer_id + target\n"
     ]
    }
   ],
   "source": [
    "# Convert embeddings to dataframe\n",
    "embedding_cols = [f'emb_{i}' for i in range(384)]\n",
    "embeddings_df = pd.DataFrame(embeddings, columns=embedding_cols)\n",
    "embeddings_df['customer_id'] = text_df['customer_id'].values\n",
    "\n",
    "# Merge with numerical features\n",
    "features_df = features_df.rename(columns={'Customer ID': 'customer_id'})\n",
    "final_df = features_df.merge(embeddings_df, on='customer_id', how='inner')\n",
    "\n",
    "print(f\"Final dataset: {final_df.shape}\")\n",
    "print(f\"Features: 12 numerical + 384 embeddings = {final_df.shape[1] - 2} features + customer_id + target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b84ffc9d-31d4-44b2-9d76-ddf2ab62b30f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4266, 396)\n",
      "y shape: (4266,)\n",
      "Target range: $0 - $287492\n",
      "Target mean: $1744\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "feature_cols = [c for c in final_df.columns if c not in ['customer_id', 'target_clv']]\n",
    "X = final_df[feature_cols]\n",
    "y = final_df['target_clv']\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"Target range: ${y.min():.0f} - ${y.max():.0f}\")\n",
    "print(f\"Target mean: ${y.mean():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "55d93e21-209a-4127-870f-ee527efceac4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3412 customers\n",
      "Test: 854 customers\n",
      "Target log range: 0.00 - 12.57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]} customers\")\n",
    "print(f\"Test: {X_test.shape[0]} customers\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Log transform target (helps with the wide range $0 - $287K)\n",
    "y_train_log = np.log1p(y_train)  # log(1 + y) handles zeros\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "print(f\"Target log range: {y_train_log.min():.2f} - {y_train_log.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f75e1aae-3caf-463d-ac68-048f35bd18c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///tmp/clv_features.parquet [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  9.1 MiB/  9.1 MiB]                                                \n",
      "Operation completed over 1 objects/9.1 MiB.                                      \n",
      "Saved features to GCS\n"
     ]
    }
   ],
   "source": [
    "# Save final dataset to GCS for next notebook\n",
    "final_df.to_parquet('/tmp/clv_features.parquet')\n",
    "\n",
    "!gsutil cp /tmp/clv_features.parquet gs://clv-prediction-data/features/clv_features.parquet\n",
    "\n",
    "print(\"Saved features to GCS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e94f1ae-8187-4572-aefc-c435c63377bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m137",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m137"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
